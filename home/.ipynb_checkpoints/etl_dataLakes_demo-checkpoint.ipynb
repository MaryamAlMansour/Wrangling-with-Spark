{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format,to_timestamp,dayofweek,from_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will parse ur creds for later access\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "# u have to specify section in your cred in order 2 configure it accuratly. in our case we called it [aws_creds]\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS_CREDS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS_CREDS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data = os.path.join(\"s3a://udacity-dend/\", \"song_data/*/*/*/*.json\" )  # because of the large data sets needed to pick one path and go with it other wise it wouldnt have been processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df = spark.read.json(song_data) \n",
    "# read song data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_table = song_df.select('artist_id', 'duration', 'song_id', 'title', 'year').dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_songs_table = songs_table.write.partitionBy(\"year\", \"artist_id\").parquet('s3/buckets/output-fact-table-data/' + \"output-songs\", \"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_table = song_df.select('artist_id', 'artist_name', 'artist_location', 'artist_latitude', 'artist_longitude').dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_artists_table = artists_table.write.parquet('s3/buckets/output-fact-table-data/' + \"output-artists\", \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = \"s3a://udacity-dend/\" + \"log_data/*.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = spark.read.json(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = log_df.filter(log_df['page'] == 'NextSong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_table = log_df.select('userId', 'firstName', 'lastName', 'gender', 'level').dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_users_table = users_table.write.parquet('s3/buckets/output-fact-table-data/' + \"users\", \"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_datetime = udf(lambda time_stamp : datetime.fromtimestamp(time_stamp/1000.0).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table = log_df.withColumn(\"date_timestamp\",get_datetime(col(\"ts\")))\n",
    "time_table.select('date_timestamp').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table = time_table.select('date_timestamp', hour('date_timestamp').alias('hour'),dayofmonth('date_timestamp').alias('day'), weekofyear('date_timestamp').alias('week'), month('date_timestamp').alias('month'),\n",
    "year('date_timestamp').alias('year'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table = time_table.select(\"date_timestamp\", \"hour\", \"day\", \"week\", \"month\", \"year\", \"weekday\").dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table = time_table.write.parquet('s3/buckets/output-fact-table-data/' + \"output-times\", \"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays_table = song_df.join(log_df, (song_df.title == log_df.song) & (song_df.duration == log_df.length) & (song_df.artist_name == log_df.artist ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays_table = songplays_table.withColumn(\"songplay_id\",monotonically_increasing_id()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays_table = songplays_table.withColumn('start_time', to_timestamp(date_format((col(\"ts\") /1000).cast(dataType=TimestampType()), \"yyyy/MM/dd HH:MM:ss z\"),\"yyyy/MM/dd HH:MM:ss z\")).select(\"songplay_id\",\"start_time\",col(\"userId\").alias(\"user_id\"),\"level\",\"song_id\",\"artist_id\",col(\"sessionId\").alias(\"session_id\"),col(\"artist_location\").alias(\"location\"),\"userAgent\",month(col(\"start_time\")).alias(\"month\"),year(col(\"start_time\")).alias(\"year\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays_table = songplays_table.write.partitionBy(\"year\", \"month\").parquet('s3/buckets/output-fact-table-data/',\"output-songplays\"),\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
